{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "\n",
    "# forward pass\n",
    "y_hat = w*x\n",
    "loss = (y_hat - y)**2\n",
    "print(loss)\n",
    "\n",
    "# backward pass\n",
    "loss.backward()\n",
    "# calculates the local gradients, and goes back to leaf nodes for backward prop\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Linear Regression (Manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# f = 2*x\n",
    "X = np.array(np.linspace(0,10, num=11), dtype=np.float32)\n",
    "Y = 3.1415*X + 2.718\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(X, Y)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, w):\n",
    "    return w[0] + w[1]*x\n",
    "\n",
    "def loss(y, y_pred, reg=0.1):\n",
    "    return np.mean((y_pred - y)**2)/2 + reg*np.mean(w[1:]**2)/(2*len(y)), reg*np.mean(w[1:]**2)/(2*len(y))\n",
    "\n",
    "# gradient\n",
    "def gradient(x, y, y_predicted, w, reg=0.1):\n",
    "    # [dw_0, dw_1]\n",
    "    return np.array([np.mean(y_predicted-y), np.mean(np.dot(2*x, y_predicted-y)) + reg*w[1]/len(y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "iters = 1000\n",
    "reg = 100\n",
    "w_ = np.array([3, 1], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 8.000\n",
      "epoch: 1 : b = 3.010, w = 2.609, loss = 81.82109694, loss_reg = 4.545\n",
      "epoch: 101 : b = 3.023, w = 3.062, loss = 42.64893521, loss_reg = 42.613\n",
      "epoch: 201 : b = 3.032, w = 3.061, loss = 42.61347064, loss_reg = 42.577\n",
      "epoch: 301 : b = 3.041, w = 3.059, loss = 42.57907646, loss_reg = 42.541\n",
      "epoch: 401 : b = 3.050, w = 3.058, loss = 42.54571316, loss_reg = 42.507\n",
      "epoch: 501 : b = 3.058, w = 3.057, loss = 42.51335308, loss_reg = 42.474\n",
      "epoch: 601 : b = 3.066, w = 3.056, loss = 42.48195214, loss_reg = 42.442\n",
      "epoch: 701 : b = 3.074, w = 3.055, loss = 42.45149600, loss_reg = 42.411\n",
      "epoch: 801 : b = 3.082, w = 3.053, loss = 42.42195320, loss_reg = 42.380\n",
      "epoch: 901 : b = 3.090, w = 3.052, loss = 42.39328883, loss_reg = 42.351\n",
      "Prediction after training: f(5) = 18.354\n"
     ]
    }
   ],
   "source": [
    "w = w_\n",
    "print(f\"Prediction before training: f(5) = {(forward(5, w)):.3f}\")\n",
    "\n",
    "for epoch in range(iters):\n",
    "    y_pred = forward(X, w)\n",
    "    l, l_reg = loss(Y, y_pred, reg)\n",
    "    dw = gradient(X, Y, y_pred, w, reg)\n",
    "    w -= alpha*dw\n",
    "    if epoch % (iters/10) == 0:\n",
    "        print(f'epoch: {epoch+1} : b = {w[0]:.3f}, w = {w[1]:.3f}, loss = {l:.8f}, loss_reg = {l_reg:.3f}')\n",
    "\n",
    "print(f\"Prediction after training: f(5) = {(forward(5, w)):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Linear Regression (Semi-Torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "Y = torch.tensor([2,4,6,8], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X):\n",
    "    return w*X\n",
    "\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted - y)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "n_iters = 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 7: w = 1.359, loss = 4.26725292\n",
      "epoch 13: w = 1.758, loss = 0.60698116\n",
      "epoch 19: w = 1.909, loss = 0.08633806\n",
      "epoch 25: w = 1.966, loss = 0.01228084\n",
      "epoch 31: w = 1.987, loss = 0.00174685\n",
      "epoch 37: w = 1.995, loss = 0.00024848\n",
      "epoch 43: w = 1.998, loss = 0.00003534\n",
      "epoch 49: w = 1.999, loss = 0.00000503\n",
      "epoch 55: w = 2.000, loss = 0.00000071\n",
      "epoch 61: w = 2.000, loss = 0.00000010\n",
      "epoch 67: w = 2.000, loss = 0.00000001\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "num = 5\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "print(f'Prediction before training: f({num}) = {forward(num):.3f}')\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    y_pred = forward(X)\n",
    "    l = loss(Y, y_pred)\n",
    "    # backward pass\n",
    "    l.backward() # dl/dw\n",
    "    dw = w.grad\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * dw\n",
    "    w.grad.zero_()\n",
    "    if epoch % (n_iters//10) == 0:\n",
    "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
    "\n",
    "print(f'Prediction after training: f({num}) = {forward(num):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Linear Regression (Near-Torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X : torch.Tensor = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "Y : torch.Tensor = torch.tensor([2,4,6,8], dtype=torch.float32)\n",
    "w = torch.tensor(0.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate : float = 0.01\n",
    "n_iters : int = 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X):\n",
    "    return w*X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch 1: w = 0.000, loss = 0.00000001\n",
      "epoch 7: w = 1.246, loss = 5.90623236\n",
      "epoch 13: w = 1.716, loss = 0.84011245\n",
      "epoch 19: w = 1.893, loss = 0.11949898\n",
      "epoch 25: w = 1.960, loss = 0.01699772\n",
      "epoch 31: w = 1.985, loss = 0.00241778\n",
      "epoch 37: w = 1.994, loss = 0.00034392\n",
      "epoch 43: w = 1.998, loss = 0.00004891\n",
      "epoch 49: w = 1.999, loss = 0.00000696\n",
      "epoch 55: w = 2.000, loss = 0.00000099\n",
      "epoch 61: w = 2.000, loss = 0.00000014\n",
      "epoch 67: w = 2.000, loss = 0.00000002\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "num = 5\n",
    "\n",
    "print(f'Prediction before training: f({num}) = {forward(num):.3f}')\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    if epoch % (n_iters//10) == 0:\n",
    "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
    "    y_pred = forward(X)\n",
    "    l = loss(Y, y_pred)\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "print(f'Prediction after training: f({num}) = {forward(num):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Linear Regression (Completely PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[1],[2],[3],[4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2],[4],[6],[8]], dtype=torch.float32)\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "n_iters = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = n_features\n",
    "output_size = n_features\n",
    "model = nn.Linear(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.tensor([5], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5.0) = 5.070\n",
      "epoch 1: w = 1.097, loss = 6.73516607\n",
      "epoch 16: w = 1.765, loss = 0.07969748\n",
      "epoch 31: w = 1.816, loss = 0.04755553\n",
      "epoch 46: w = 1.827, loss = 0.04335935\n",
      "epoch 61: w = 1.835, loss = 0.03962892\n",
      "epoch 76: w = 1.842, loss = 0.03621986\n",
      "epoch 91: w = 1.849, loss = 0.03310408\n",
      "epoch 106: w = 1.856, loss = 0.03025628\n",
      "epoch 121: w = 1.862, loss = 0.02765350\n",
      "epoch 136: w = 1.868, loss = 0.02527460\n",
      "Prediction after training: f(5.0) = 9.739\n"
     ]
    }
   ],
   "source": [
    "print(f'Prediction before training: f({X_test[0].item()}) = {model(X_test).item():.3f}')\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    y_pred = model(X)\n",
    "    l = loss(Y, y_pred)\n",
    "    l.backward()\n",
    "    # I don't understand how is loss and the optimizer connected?\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if epoch % (n_iters//10) == 0:\n",
    "        [w, b] = model.parameters()\n",
    "        print(f'epoch {epoch+1}: w = {w[0][0].item():.3f}, loss = {l:.8f}')\n",
    "\n",
    "print(f'Prediction after training: f({X_test[0].item()}) = {model(X_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom linear regression model\n",
    "class LinearRegress(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegress, self).__init__()\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegress(input_size, output_size)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80368f23d0b702c79dfe36020914814c563de0a4219ae0904a6558b886cfd7bb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
